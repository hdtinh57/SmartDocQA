import streamlit as st
import os
import tempfile
from core.rag_pipeline import RagPipeline

# --- Page Config ---
st.set_page_config(
    page_title="Smart Document Q&A System",
    page_icon="ü§ñ",
    layout="wide"
)

# --- Initialization ---
@st.cache_resource
def get_pipeline():
    # Cache the pipeline so models (like BGE-M3) are loaded only once
    return RagPipeline(use_local_vlm=False)

def initialize_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "pipeline" not in st.session_state:
        st.session_state.pipeline = get_pipeline()
    if "processed_files" not in st.session_state:
        # L·∫•y danh s√°ch t√†i li·ªáu ƒë√£ c√≥ s·∫µn t·ª´ Qdrant ƒë·ªÉ hi·∫øn th·ªã
        docs = st.session_state.pipeline.vdb.get_all_documents()
        st.session_state.processed_files = docs

initialize_session_state()

# --- Custom CSS ---
st.markdown("""
<style>
    .reportview-container {
        margin-top: -2em;
    }
    .stDeployButton {display:none;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- Sidebar ---
with st.sidebar:
    st.title("üìÇ Upload Documents")
    st.markdown("h·ªó tr·ª£ ƒë·ªãnh d·∫°ng PDF, PNG, JPG, JPEG.")
    
    uploaded_file = st.file_uploader("Upload file here", type=["pdf", "png", "jpg", "jpeg"])
    
    if st.button("Process Document", type="primary"):
        if uploaded_file is not None:
            # Save uploaded file permanently to view later
            os.makedirs("data/uploaded_docs", exist_ok=True)
            save_path = os.path.join("data/uploaded_docs", uploaded_file.name)
            with open(save_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
                
            # Ki·ªÉm tra xem file ƒë√£ c√≥ trong DB ch∆∞a (tr√™n giao di·ªán cache ho·∫∑c qu√©t Qdrant tr·ª±c ti·∫øp)
            if uploaded_file.name in st.session_state.processed_files or st.session_state.pipeline.vdb.has_document(uploaded_file.name):
                st.warning(f"T√†i li·ªáu '{uploaded_file.name}' ƒë√£ c√≥ s·∫µn trong c∆° s·ªü d·ªØ li·ªáu! B·∫°n c√≥ th·ªÉ ƒë·∫∑t c√¢u h·ªèi ho·∫∑c xem t√†i li·ªáu ngay.")
                if uploaded_file.name not in st.session_state.processed_files:
                    st.session_state.processed_files.append(uploaded_file.name)
            else:
                with st.spinner(f"ƒêang x·ª≠ l√Ω {uploaded_file.name}... (OCR & VectorEmbedding)"):
                    # Run Ingestion Pipeline
                    success = st.session_state.pipeline.ingest_document(
                        file_path=save_path, 
                        source_name=uploaded_file.name
                    )
                    
                    if success:
                        st.session_state.processed_files.append(uploaded_file.name)
                        st.success(f"X·ª≠ l√Ω th√†nh c√¥ng: {uploaded_file.name}")
                    else:
                        st.error(f"X·ª≠ l√Ω th·∫•t b·∫°i: {uploaded_file.name}. Vui l√≤ng ki·ªÉm tra API Key (Mistral) trong file .env")
        else:
            st.error("Vui l√≤ng upload m·ªôt file tr∆∞·ªõc khi nh·∫•n Process.")
            
    st.divider()
    st.markdown("### üìö T√†i li·ªáu ƒë√£ l∆∞u")
    if st.session_state.processed_files:
        for file in list(st.session_state.processed_files):
            col1, col2 = st.columns([8, 2])
            with col1:
                st.markdown(f"üìÑ `{file}`")
            with col2:
                if st.button("‚ùå", key=f"del_{file}", help="X√≥a t√†i li·ªáu"):
                    # X√≥a vector t·ª´ Qdrant
                    st.session_state.pipeline.vdb.delete_document(file)
                    st.session_state.processed_files.remove(file)
                    # X√≥a file v·∫≠t l√Ω
                    try:
                        os.remove(os.path.join("data", "uploaded_docs", file))
                        os.remove(os.path.join("data", "ocr_results", f"{file}.txt"))
                    except:
                        pass
                    st.rerun()
    else:
        st.markdown("*Ch∆∞a c√≥ t√†i li·ªáu n√†o*")

# --- Main Layout ---
st.title("ü§ñ Tr·ª£ l√Ω AI h·ªèi ƒë√°p t√†i li·ªáu th√¥ng minh (RAG)")
st.markdown("H√£y upload t√†i li·ªáu ·ªü thanh b√™n tr√°i (Sidebar) tr∆∞·ªõc khi ƒë·∫∑t c√¢u h·ªèi ƒë·ªÉ AI c√≥ ng·ªØ c·∫£nh.")

tab1, tab2 = st.tabs(["üí¨ Chat & Q&A", "üìÑ Xem t√†i li·ªáu (B·∫£n g·ªëc & OCR)"])

with tab1:
    # Display chat messages from history
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- Chat Input ---
    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ t√†i li·ªáu..."):
        # Add user message to state and display
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate assistant response
        with st.chat_message("assistant"):
            with st.spinner("ƒêang t√¨m ki·∫øm th√¥ng tin v√† suy nghƒ©..."):
                response = st.session_state.pipeline.ask(prompt, allowed_sources=st.session_state.processed_files)
                st.markdown(response)
                
        st.session_state.messages.append({"role": "assistant", "content": response})

with tab2:
    st.header("Chi ti·∫øt t√†i li·ªáu")
    if not st.session_state.processed_files:
        st.info("Ch∆∞a c√≥ t√†i li·ªáu n√†o trong h·ªá th·ªëng. H√£y upload t√†i li·ªáu ·ªü c·ªôt tr√°i.")
    else:
        selected_doc = st.selectbox("Ch·ªçn t√†i li·ªáu ƒë·ªÉ xem:", st.session_state.processed_files)
        if selected_doc:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("B·∫£n g·ªëc")
                doc_path = os.path.join("data", "uploaded_docs", selected_doc)
                if os.path.exists(doc_path):
                    ext = os.path.splitext(doc_path)[1].lower()
                    if ext == ".pdf":
                        # Display PDF using base64 embed
                        import base64
                        with open(doc_path, "rb") as f:
                            base64_pdf = base64.b64encode(f.read()).decode('utf-8')
                        pdf_display = f'<embed src="data:application/pdf;base64,{base64_pdf}" width="100%" height="800px" type="application/pdf" />'
                        st.markdown(pdf_display, unsafe_allow_html=True)
                    elif ext in [".png", ".jpg", ".jpeg"]:
                        st.image(doc_path, use_container_width=True)
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y file g·ªëc tr√™n m√°y ch·ªß (C√≥ th·ªÉ ƒë√£ b·ªã x√≥a ho·∫∑c ƒë∆∞·ª£c x·ª≠ l√Ω t·ª´ thi·∫øt b·ªã kh√°c). B·∫°n c√≥ th·ªÉ th·ª≠ upload l·∫°i file ƒë√≥ ƒë·ªÉ xem.")
            
            with col2:
                st.subheader("K·∫øt qu·∫£ OCR")
                ocr_path = os.path.join("data", "ocr_results", f"{selected_doc}.txt")
                if os.path.exists(ocr_path):
                    with open(ocr_path, "r", encoding="utf-8") as f:
                        ocr_text = f.read()
                    st.text_area("VƒÉn b·∫£n nh·∫≠n di·ªán ƒë∆∞·ª£c (c√≥ th·ªÉ ch·ªânh s·ª≠a ƒë·ªÉ ki·ªÉm tra):", value=ocr_text, height=600)
                else:
                    st.warning("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ OCR l∆∞u tr·ªØ cho t√†i li·ªáu n√†y (C√≥ th·ªÉ qu√° tr√¨nh OCR l·∫ßn tr∆∞·ªõc b·ªã l·ªói ho·∫∑c file text ƒë√£ b·ªã x√≥a).")
